{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SpamText-NB and DT.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aruntahilramani/134_ArunTahilramani/blob/master/Lab4/Ex3_SpamText_NB_and_DT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFYK4zo9kojK",
        "outputId": "c6168f72-6b01-45af-ac9d-ce2d33b7f8a3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrZevCPJ92HG"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rmYBjsyCv3K"
      },
      "source": [
        "dataset = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/ML/Lab4/spam.csv') \n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkvmsbgkNRe4"
      },
      "source": [
        "## Analysis\n",
        "\n",
        "To analyze the text data, we have to turn the words into numerical numbers. \n",
        "We have multiple choices to accomplish this step: \n",
        "\n",
        "1) Binary Term Frequency :  count presence(1) or absence(0) for term in document\n",
        "\n",
        "2) Bag of Words Frequency:  captures the frequency of term in document\n",
        "\n",
        "3) Term Frequency: \n",
        "\n",
        "4) TFIDF :\n",
        "\n",
        "in this way, if a term appears frequently in a document, it’s important; if a term appears in many documents, it’s not a unique identifier.\n",
        "\n",
        "useful links :\n",
        "\n",
        "- https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
        "- https://towardsdatascience.com/tf-idf-for-document-ranking-from-scratch-in-python-on-real-world-dataset-796d339a4089\n",
        "- https://machinelearningmastery.com/gentle-introduction-bag-words-model/\n",
        "- https://towardsdatascience.com/hacking-scikit-learns-vectorizers-9ef26a7170af\n",
        "- https://towardsdatascience.com/top-5-word-tokenizers-that-every-nlp-data-scientist-should-know-45cc31f8e8b9"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVEdyrxEkmE4",
        "outputId": "403c0eb4-9368-4155-dafb-efbd2e89ac24"
      },
      "source": [
        "print(\"\\nData :\\n\",dataset)\n",
        "print(\"\\nData statistics\\n\",dataset.info())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Data :\n",
            "         v1                                                 v2\n",
            "0      ham  Go until jurong point, crazy.. Available only ...\n",
            "1      ham                      Ok lar... Joking wif u oni...\n",
            "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
            "3      ham  U dun say so early hor... U c already then say...\n",
            "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
            "...    ...                                                ...\n",
            "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
            "5568   ham              Will �_ b going to esplanade fr home?\n",
            "5569   ham  Pity, * was in mood for that. So...any other s...\n",
            "5570   ham  The guy did some bitching but I acted like i'd...\n",
            "5571   ham                         Rofl. Its true to its name\n",
            "\n",
            "[5572 rows x 2 columns]\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5572 entries, 0 to 5571\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   v1      5572 non-null   object\n",
            " 1   v2      5571 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 87.2+ KB\n",
            "\n",
            "Data statistics\n",
            " None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQYQA_LkkmE6",
        "outputId": "92c9e4f2-2b0f-4a24-c010-98e95299b263"
      },
      "source": [
        "dataset.dropna(how='any',inplace=True)\n",
        "print(dataset.isnull().sum())\n",
        "dataset.drop_duplicates(inplace=True)\n",
        "print(dataset.duplicated().any())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "v1    0\n",
            "v2    0\n",
            "dtype: int64\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbhXzh5ONQ5R"
      },
      "source": [
        "# Preprocessing"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0K370KCSkmE7"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import nltk\n",
        "import string\n",
        "import re\n",
        "import random"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "wLfAZ6YzkmE8"
      },
      "source": [
        "re.findall(r\"[a-z]+\", \"123ram=*kisanw217-+/\") "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WScocjg-kmE9"
      },
      "source": [
        "def stemWords(list1):\n",
        "    #     stemmer=nltk.stem.PorterStemmer()\n",
        "    stemmer=nltk.stem.SnowballStemmer('english')\n",
        "    #     leminizer.lemmatize(word)\n",
        "    #     stemmer = nltk.stem.ISRIStemmer()\n",
        "    #     leminizer = nltk.stem.WordNetLemmatizer()\n",
        "    #     stemmer = nltk.stem.LancasterStemmer()\n",
        "    \n",
        "    words=[]\n",
        "    for text in list1:\n",
        "        for word in re.findall(r\"[a-z]+\",text):\n",
        "            if (len(word)>2 and word not in string.punctuation):\n",
        "                words.append(stemmer.stem(word))\n",
        "    return words\n",
        "    \n",
        "def my_tokenizer(text):\n",
        "#     tokens=nltk.tokenize.TreebankWordTokenizer().tokenize(text)\n",
        "#     tokens=nltk.tokenize.word_tokenize(text)\n",
        "    tokens =nltk.tokenize.wordpunct_tokenize(text)\n",
        "    \n",
        "    newtokens= stemWords(tokens)\n",
        "    \n",
        "    return newtokens\n",
        "\n",
        "def convert_to_sparse_pandas(df, exclude_columns=[]):\n",
        "    \"\"\"\n",
        "    Converts columns of a data frame into SparseArrays and returns the data frame with transformed columns.\n",
        "    Use exclude_columns to specify columns to be excluded from transformation.\n",
        "    :param df: pandas data frame\n",
        "    :param exclude_columns: list\n",
        "        Columns not be converted to sparse\n",
        "    :return: pandas data frame\n",
        "    \"\"\"\n",
        "    df = pd.DataFrame()\n",
        "    exclude_columns = set(exclude_columns)\n",
        "\n",
        "    for (columnName, columnData) in df.iteritems():\n",
        "        if columnName in exclude_columns:\n",
        "            continue\n",
        "        df[columnName] = pd.arrays.SparseArray(columnData.values, dtype='uint8')\n",
        "\n",
        "    return df"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "zXEKUDIBkmE-"
      },
      "source": [
        "my_tokenizer(dataset['v2'][0])"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ss-sa1dTliz5",
        "outputId": "e29c2928-e975-400a-dc3f-dfd007ef4d9a"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VW9J78vWkmE-",
        "outputId": "fc778777-80b0-43cf-f936-b969387ec0f6"
      },
      "source": [
        "vectorizer = CountVectorizer(stop_words=nltk.corpus.stopwords.words('english'),tokenizer=my_tokenizer,ngram_range=(1,1))\n",
        "X = vectorizer.fit_transform(dataset['v2'])\n",
        "tokens=vectorizer.get_feature_names()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'becaus', 'befor', 'doe', 'dure', 'onc', 'onli', 'ourselv', 'themselv', 'veri', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "laf_VWBJkmE-",
        "outputId": "b012669b-9def-4645-de97-5d501fcff66e"
      },
      "source": [
        "len(tokens)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5847"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCXw1vAhkmE_"
      },
      "source": [
        "Labels = dataset['v1']\n",
        "Data = pd.DataFrame(data=X.toarray(),columns=tokens)\n",
        "SparseData = Data.astype(pd.SparseDtype(np.int16))\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LzG1K6WkmE_",
        "outputId": "fa29dad1-4f81-4561-ad74-5f5c546f92bc"
      },
      "source": [
        "r = random.randint(0,Data.shape[1]-1)\n",
        "print(r)\n",
        "print(np.unique(Data.iloc[:,r]))\n",
        "print(Data.memory_usage().sum()*pow(10,-6)*3, \" mb\")\n",
        "print(dataset.memory_usage().sum()*pow(10,-6)*3,\" mb\")\n",
        "print(SparseData.memory_usage().sum()*pow(10,-6)*3,\" mb\")\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2587\n",
            "[0 1]\n",
            "724.513848  mb\n",
            "0.37173599999999996  mb\n",
            "0.679704  mb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNsQ3db7kmFA"
      },
      "source": [
        "encoder = LabelEncoder()\n",
        "Labels = encoder.fit_transform(Labels)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgdC2wNQkmFA",
        "outputId": "5b6fe321-7bc3-4010-85ac-ff2a3ccd0ab4"
      },
      "source": [
        "print(Data.shape)\n",
        "print(SparseData.shape)\n",
        "print(dataset.shape)\n",
        "print(Labels.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5163, 5847)\n",
            "(5163, 5847)\n",
            "(5163, 2)\n",
            "(5163,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "OlNgEO4mkmFA"
      },
      "source": [
        "print(Labels)\n",
        "print(SparseData)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBivurCekmFB"
      },
      "source": [
        "# Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8OHV4HlkmFB"
      },
      "source": [
        "from sklearn.metrics import classification_report\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9vB3hKHIEFr"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data_train, data_test, target_train, target_test = train_test_split(SparseData,\n",
        "                        Labels, test_size = 0.30, random_state = 134)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcC9U7_DHw03"
      },
      "source": [
        "**Naive Bayes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZAmSYVKIWG5"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsiHGRNbkmFC"
      },
      "source": [
        "data_train, data_test, target_train, target_test = train_test_split(Data,\n",
        "                        Labels, test_size = 0.30, random_state = 134)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJrevf0zkmFC",
        "outputId": "ed1fd72a-b358-4858-b14f-3fcb099bd60a"
      },
      "source": [
        "gnb = GaussianNB()\n",
        "gnb.fit(data_train,target_train)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB(priors=None, var_smoothing=1e-09)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gYXY49OkmFD"
      },
      "source": [
        "target_pred = gnb.predict(data_test)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnw3MQymkmFD",
        "outputId": "f65ace59-c940-44b0-fa02-2da26b0c0e4a"
      },
      "source": [
        "print(classification_report(target_test,target_pred))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.84      0.90      1347\n",
            "           1       0.44      0.83      0.57       202\n",
            "\n",
            "    accuracy                           0.84      1549\n",
            "   macro avg       0.70      0.83      0.74      1549\n",
            "weighted avg       0.90      0.84      0.86      1549\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYu4_PnbIxfw"
      },
      "source": [
        "**Decision Tree**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqjGef-FIw7U"
      },
      "source": [
        "from sklearn import tree"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3PD4ITdkmFD"
      },
      "source": [
        "mytree = tree.DecisionTreeClassifier(random_state=134,max_depth=20,max_leaf_nodes=242)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90Zcvl63kmFE",
        "outputId": "c71aeeda-d1dc-4b82-ff7d-82a344f2d27c"
      },
      "source": [
        "mytree.fit(data_train,target_train)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
              "                       max_depth=20, max_features=None, max_leaf_nodes=242,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=134, splitter='best')"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4i2Eyy1fkmFE"
      },
      "source": [
        "target_pred=mytree.predict(data_test)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bmimQeBkmFE",
        "outputId": "9edd9afc-dd1c-4f54-cc5f-f69d0f5d5f99"
      },
      "source": [
        "print(classification_report(target_test,target_pred))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.98      1347\n",
            "           1       0.90      0.75      0.82       202\n",
            "\n",
            "    accuracy                           0.96      1549\n",
            "   macro avg       0.93      0.87      0.90      1549\n",
            "weighted avg       0.96      0.96      0.95      1549\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3i5VpsczbgsS"
      },
      "source": [
        "**Optional Exercise:**\n",
        "Try this on full spam.csv file and bigram matching instead of unigram matching "
      ]
    }
  ]
}
